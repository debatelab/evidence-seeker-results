claims: []
confirmation_config:
  config_version: v0.2
  description: Configuration of EvidenceSeeker's confirmation analyzer component.
  env_file: null
  freetext_confirmation_analysis:
    description: Instruct the assistant to carry out free-text RTE analysis.
    llm_specific_configs:
      default:
        prompt_template: 'Determine the relationship between the following two texts:

          <TEXT>{evidence_item}</TEXT>


          <HYPOTHESIS>{statement}</HYPOTHESIS>

          Does the TEXT entail, contradict, or neither entail nor contradict the HYPOTHESIS?

          Classify the relationship as one of the following:

          Entailment: The TEXT provides sufficient evidence to support the HYPOTHESIS.

          Contradiction: The TEXT provides evidence that contradicts the HYPOTHESIS.

          Neutral: The TEXT neither supports nor contradicts the HYPOTHESIS.

          Please discuss this question thoroughly before providing your final answer.'
        system_prompt: null
    name: freetext_confirmation_analysis
    used_model_key: null
  models:
    together.ai:
      api_key_name: hf_debatelab_inference_provider
      backend_type: openai
      base_url: https://router.huggingface.co/together/v1
      default_headers:
        X-HF-Bill-To: DebateLabKIT
      description: Model served via Together.ai over HuggingFace
      max_tokens: 1024
      model: meta-llama/Llama-3.2-3B-Instruct-Turbo
      name: Meta-Llama-3-Instruct
      temperature: 0.2
      timeout: 260
  multiple_choice_confirmation_analysis:
    description: Multiple choice RTE task given CoT trace.
    llm_specific_configs:
      default:
        answer_labels:
        - A
        - B
        - C
        answer_options:
        - 'Entailment: The TEXT provides sufficient evidence to support the HYPOTHESIS.'
        - 'Contradiction: The TEXT provides evidence that contradicts the HYPOTHESIS.'
        - 'Neutral: The TEXT neither supports nor contradicts the HYPOTHESIS.'
        claim_option: 'Entailment: The TEXT provides sufficient evidence to support
          the HYPOTHESIS.'
        constrained_decoding_grammar: null
        constrained_decoding_regex: null
        delim_str: ''
        guidance_type: json
        json_schema:
          properties:
            answer:
              pattern: ^(A|B|C)$
              type: string
          required:
          - answer
        logprobs_type: openai_like
        n_repetitions_mcq: 1
        prompt_template: 'Your task is to sum up the results of a rich textual entailment
          analysis.


          <TEXT>{evidence_item}</TEXT>


          <HYPOTHESIS>{statement}</HYPOTHESIS>


          Our previous analysis has yielded the following result:


          <RESULT>

          {freetext_confirmation_analysis}

          </RESULT>


          Please sum up this result by deciding which of the following choices is
          correct. Just answer with the label of the correct choice.


          {answer_options}


          '
        system_prompt: null
        validation_regex: null
    name: multiple_choice_confirmation_analysis
    used_model_key: null
  system_prompt: 'You are a helpful assistant with outstanding expertise in critical
    thinking and logico-semantic analysis.

    You have a background in philosophy and experience in fact checking and debate
    analysis.

    You read instructions carefully and follow them precisely. You give concise and
    clear answers.'
  timeout: 900
  used_model_key: together.ai
  verbose: false
feedback:
  binary: null
preprocessing_config:
  config_version: v0.1
  description: Configuration of EvidenceSeeker's preprocessing component.
  env_file: null
  freetext_ascriptive_analysis:
    description: Instruct the assistant to carry out free-text ascriptions analysis.
    llm_specific_configs:
      default:
        guidance_type: null
        prompt_template: 'The following {language} claim has been submitted for fact-checking.


          <claim>{claim}</claim>


          Before we proceed with retrieving evidence items, we carefully analyse the
          claim. Your task is to contribute to this preparatory analysis, as detailed
          below.

          In particular, you should thoroughly discuss whether the claim makes any
          explicit ascriptions, that is, whether it explicitly ascribes a statement
          to a person or an organisation (e.g., as something the person has said,
          believes, acts on etc.) rather than plainly asserting that statement straightaway.

          If so, clarify which statements are ascribed to whom exactly and in which
          ways.

          In doing so, watch out for ambiguity and vagueness in the claim. Make alternative
          interpretations explicit.

          Conclude your analysis with a short list of all identified ascriptions:
          Formulate each statement in a concise manner, and such that it is transparent
          to whom it is attributed. Render the clarified ascriptions in {language}.'
        system_prompt: null
    name: freetext_ascriptive_analysis
    used_model_key: null
  freetext_descriptive_analysis:
    description: Instruct the assistant to carry out free-text factual/descriptive
      analysis.
    llm_specific_configs:
      default:
        guidance_type: null
        prompt_template: 'The following {language} claim has been submitted for fact-checking.


          <claim>{claim}</claim>


          Before we proceed with retrieving evidence items, we carefully analyse the
          claim. Your task is to contribute to this preparatory analysis, as detailed
          below.

          In particular, you should thoroughly discuss whether the claim contains
          or implies factual or descriptive statements, which can be verified or falsified
          by empirical observation or through scientific analysis, and which may include,
          for example, descriptive reports, historical facts, or scientific claims.

          If so, try to identify them and render them in your own words.

          In doing so, watch out for ambiguity and vagueness in the claim. Make alternative
          interpretations explicit.

          End your analysis with a short list of all identified factual or descriptive
          statements in {language}. Formulate each statement in a concise manner and
          such that its factual nature stands out clearly.'
        system_prompt: null
    name: freetext_descriptive_analysis
    used_model_key: null
  freetext_normative_analysis:
    description: Instruct the assistant to carry out free-text normative analysis.
    llm_specific_configs:
      default:
        guidance_type: null
        prompt_template: 'The following {language} claim has been submitted for fact-checking.


          <claim>{claim}</claim>


          Before we proceed with retrieving evidence items, we carefully analyse the
          claim. Your task is to contribute to this preparatory analysis, as detailed
          below.

          In particular, you should thoroughly discuss whether the claim contains
          or implies normative statements, such as value judgements, recommendations,
          or evaluations. If so, try to identify them and render them in your own
          words.

          In doing so, watch out for ambiguity and vagueness in the claim. Make alternative
          interpretations explicit. However, avoid reading normative content into
          the claim without textual evidence.


          End your analysis with a short list of all identified normative statements
          in {language}. Formulate each statement in a concise manner and such that
          its normative nature stands out clearly.'
        system_prompt: null
    name: freetext_normative_analysis
    used_model_key: null
  language: DE
  list_ascriptive_statements:
    description: Instruct the assistant to list ascriptions.
    llm_specific_configs:
      default:
        guidance_type: json
        prompt_template: 'The following {language} claim has been submitted for ascriptive
          content analysis.

          <claim>{claim}</claim>

          The analysis yielded the following results:


          <results>

          {ascriptive_analysis}

          </results>


          Your task is to list all ascriptions identified in this analysis. Clearly
          state each ascription as a concise {language} statement, such that it is
          transparent to whom it is attributed. Only include ascriptions that are
          explicitly attributed to a specific person or organisation.

          Format your (possibly empty) list of statements as a JSON object.

          Do not include any other text than the JSON object.'
        system_prompt: null
    name: list_ascriptive_statements
    used_model_key: null
  list_descriptive_statements:
    description: Instruct the assistant to list factual claims.
    llm_specific_configs:
      default:
        guidance_type: json
        prompt_template: 'We have previously analysed the descriptive content of the
          following {language} claim:

          <claim>{claim}</claim>

          The analysis yielded the following results:


          <results>

          {descriptive_analysis}

          </results>


          Your task is to list all factual or descriptive {language} statements identified
          in the previous analysis. Only include clear cases, i.e. statements that
          are unambiguously factual or descriptive.

          Format your (possibly empty) list of statements as a JSON object.

          Do not include any other text than the JSON object.'
        system_prompt: null
    name: list_descriptive_statements
    used_model_key: null
  list_normative_statements:
    description: Instruct the assistant to list normative claims.
    llm_specific_configs:
      default:
        guidance_type: json
        prompt_template: 'The following {language} claim has been submitted for normative
          content analysis.

          <claim>{claim}</claim>

          The analysis yielded the following results:


          <results>

          {normative_analysis}

          </results>


          Your task is to list all normative statements identified in this analysis
          (e.g., value judgements, recommendations, or evaluations) in {language}.

          Format your (possibly empty) list of statements as a JSON object.

          Do not include any other text than the JSON object.'
        system_prompt: null
    name: list_normative_statements
    used_model_key: null
  models:
    together.ai:
      api_key_name: hf_debatelab_inference_provider
      backend_type: openai
      base_url: https://router.huggingface.co/together/v1
      default_headers:
        X-HF-Bill-To: DebateLabKIT
      description: Model served via Together.ai over HuggingFace
      max_tokens: 1024
      model: meta-llama/Llama-3.2-3B-Instruct-Turbo
      name: Meta-Llama-3-Instruct
      temperature: 0.2
      timeout: 260
  negate_claim:
    description: Instruct the assistant to negate a claim.
    llm_specific_configs:
      default:
        guidance_type: null
        prompt_template: 'Your task is to express the opposite of the following statement
          in plain and unequivocal language.

          Please generate a single {language} sentence that clearly states the negation.

          <statement>

          {statement}

          </statement>

          Provide only the negated statement in {language} without any additional
          comments.'
        system_prompt: null
    name: negate_claim
    used_model_key: null
  system_prompt: "You are a helpful assistant with outstanding expertise in critical\
    \ thinking and logico-semantic analysis. \nYou have a background in philosophy\
    \ and experience in fact checking and debate analysis.\nYou read instructions\
    \ carefully and follow them precisely. You give concise and clear answers."
  timeout: 900
  used_model_key: together.ai
  verbose: false
request: Die Genfer Konventionen sind oft hinter ihrem Anspruch, die Zivilbevölkerung
  zu schützen, zurückgeblieben.
request_time: 2025-08-03 13:22:26 UTC
request_uid: 21b7e843-8a56-4031-be63-85e16ffb8641
retrieval_config:
  api_key_name: hf_debatelab_inference_provider
  bill_to: DebateLabKIT
  config_version: v0.1
  description: Erste Version einer Konfiguration für den Retriever der EvidenceSeeker
    Boilerplate.
  document_input_dir: null
  document_input_files: null
  embed_backend_type: huggingface_inference_api
  embed_base_url: https://router.huggingface.co/hf-inference/models/sentence-transformers/paraphrase-multilingual-mpnet-base-v2
  embed_batch_size: 32
  embed_model_name: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
  env_file: null
  hub_key_name: hf_debatelab_inference_provider
  ignore_statement_types:
  - normative
  index_hub_path: DebateLabKIT/apuz-index-es
  index_id: default_index_id
  index_persist_path: null
  meta_data_file: null
  top_k: 8
  window_size: 3
